<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mind Captioning Project</title>
  <style>
    body {
      font-family: 'Helvetica Neue', sans-serif;
      margin: 0;
      padding: 0;
      background: #f4f4f4;
      color: #222;
      line-height: 1.7;
      font-size: 1.1rem;
      text-align: center;
    }
    header {
      background: #ffffff;
      padding: 2rem 1rem;
      border-bottom: 1px solid #ddd;
    }
    header h1 {
      font-size: 2.8rem;
      font-weight: 700;
      margin-bottom: 0.5rem;
      line-height: 1.3;
      white-space: pre-line;
    }
    .author {
      font-size: 1.1rem;
      margin-bottom: 1rem;
      color: #444;
    }
    .meta {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 1.5rem;
      font-size: 1rem;
      color: #444;
      margin-bottom: 1.5rem;
    }
    .meta a {
      color: #005577;
      text-decoration: none;
    }
    main {
      max-width: 1800px;
      margin: 2rem auto;
      padding: 2rem;
      background: #ffffff;
      border-radius: 12px;
      box-shadow: 0 6px 24px rgba(0, 0, 0, 0.06);
    }
    h2 {
      font-size: 1.6rem;
      font-weight: 600;
      padding-left: 0.6rem;
      margin-top: 2.5rem;
      color: #333;
      text-align: left;
      display: inline-block;
    }
    section {
      margin-bottom: 2rem;
    }
    .centered-image img {
      width: 80%;
      max-width: 900px;
      border-radius: 6px;
      margin: 1rem auto;
      display: block;
    }
    .video-block video {
      width: 80%;
      max-width: 900px;
      border-radius: 6px;
      margin: 0.5rem auto;
      display: block;
    }
    .video-block p.title,
    .video-sub p.title {
      font-weight: bold;
      font-size: 1.1rem;
      margin-top: 1rem;
      margin-bottom: 0.5rem;
    }
    .video-block p.caption,
    .video-sub p.caption {
      font-size: 1.05rem;
      color: #444;
      width: 80%;
      max-width: 900px;
      margin: 0.5rem auto 1rem auto;
    }
    .video-pair {
      display: flex;
      gap: 2rem;
      justify-content: center;
      flex-wrap: wrap;
    }
    .video-sub {
      flex: 1;
      max-width: 600px;
    }
    .video-sub video {
      width: 100%;
      border-radius: 6px;
    }
    a {
      color: #005577;
    }
  </style>
</head>
<body>
  <header>
    <h1>Mind Captioning: Evolving descriptive text
of mental content from human brain activity</h1>
    <div class="author">Tomoyasu Horikawa, NTT Communication Science Laboratories</div>
    <div class="meta">
      <a href="https://www.biorxiv.org/content/10.1101/2024.04.23.590673v2">Preprint</a>
      <a href="https://github.com/horikawa-t/MindCaptioning">Code</a>
      <a href="https://doi.org/10.18112/openneuro.ds005191.v1.0.2">Raw data</a>
      <a href="https://doi.org/10.6084/m9.figshare.25808179">Preprocessed data</a>
    </div>
    <div class="caption" style="max-width: 800px; margin: 2rem auto 0 auto; font-size: 1.05rem; color: #444; text-align: left;">A central challenge in neuroscience is decoding brain activity to uncover mental content comprising multiple components and their interactions. Despite progress in decoding language-related information from human brain activity, generating comprehensive descriptions of complex mental content associated with structured visual semantics remains challenging. We present a method that generates descriptive text mirroring brain representations via semantic features computed by a deep language model. Constructing linear decoding models to translate brain activity induced by videos into semantic features of corresponding captions, we optimized candidate descriptions by aligning their features with brain-decoded features through word replacement and interpolation. This process yielded well-structured descriptions accurately capturing viewed content, even without relying on the canonical language network, suggesting the feasibility of translating non-verbal visual semantics to linguistic outputs. The method also successfully generalized to verbalize recalled content, demonstrating the potential for non-verbal thought-based brain-to-text communication, which could aid individuals with language expression difficulties.
      </div>
  </header>
  <main style="padding-top: 2rem;">
    <section style="margin: 4rem auto; padding: 2rem 0; border-top: 1px solid #eee; max-width: 960px;">
      <h2>研究概要</h2>
      <p class="caption" style="max-width: 600px; margin: 0 auto; text-align: left;">本研究では，fMRIデータから言語的記述（キャプション）を直接生成する「Mind Captioning」技術を開発しました．この手法は，視聴中あるいは想起中の脳活動から意味特徴を予測し，その意味に整合するように深層言語モデルを最適化することで，自由記述的な文を生成することを可能にします．</p>
    </section>
    <section style="margin: 4rem auto; padding: 2rem 0; border-top: 1px solid #eee; max-width: 960px;">
      <h2>研究の全体像</h2>
      <div class="centered-image">
        <img src="overview.png" alt="研究の概要図">
      </div>
      <p class="caption" style="max-width: 600px; margin: 0 auto; text-align: left;">図は，視覚刺激の提示・想起時に得られた脳活動からキャプションを生成する全体フローを示しています．</p>
    </section>
    <section style="margin: 4rem auto; padding: 2rem 0; border-top: 1px solid #eee; max-width: 960px;">
      <h2>主な成果</h2>
      <div class="video-block">
        <p class="title">視覚内容の最適化プロセス</p>
        <video controls src="https://figshare.com/ndownloader/files/50289609"></video>
        <!-- <video controls src="Supplementary_Movie1.mov"></video> -->
        <p class="caption" style="max-width: 700px; margin: 0 auto; text-align: left;">提示された映像内容に対するキャプションが、最適化を通じてどのように進化していくかを示します。</p>
      </div>
      <div class="video-pair">
        <div class="video-sub">
          <p class="title">視覚内容のキャプション（全被験者）</p>
          <video controls src="https://figshare.com/ndownloader/files/50289612"></video>
          <!-- <video controls src="Supplementary_Movie2.mov"></video> -->
          <p class="caption" style="max-width: 700px; margin: 0 auto; text-align: left;">提示された映像に対して生成されたキャプションの例を、複数被験者について示します。</p>
        </div>
        <div class="video-sub">
          <p class="title">想起内容のキャプション（全被験者）</p>
          <video controls src="https://figshare.com/ndownloader/files/50289615"></video>
          <!-- <video controls src="Supplementary_Movie3.mov"></video> -->
          <p class="caption" style="max-width: 700px; margin: 0 auto; text-align: left;">想起された内容に対して生成されたキャプションの例を、複数被験者について示します。</p>
        </div>
      </div>
    </section>
    <section style="margin: 4rem auto; padding: 2rem 0; border-top: 1px solid #eee; max-width: 960px;">
      <h2>お問い合わせ</h2>
      <p style="max-width: 600px; margin: 0 auto; text-align: left;">本研究に関するお問い合わせは <a href="mailto:your.email@example.com">your.email@example.com</a> までご連絡ください。</p>
    </section>
  </main>
</body>
</html>
